{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "Copy of 01_matmul.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "DeAwZ09yCaW2",
        "BeO7QbTYBAyv",
        "6vqAGswhCaYA"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvrebellion/20191204_VITTORIA_ML/blob/main/Copy_of_01_matmul.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeAwZ09yCaW2"
      },
      "source": [
        "## Matrix multiplication from foundations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZtC2bZPCaXh"
      },
      "source": [
        "The *foundations* we'll assume throughout this course are:\n",
        "\n",
        "- Python\n",
        "- Python modules (non-DL)\n",
        "- pytorch indexable tensor, and tensor creation (including RNGs - random number generators)\n",
        "- fastai.datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4sw4cNx3bP1"
      },
      "source": [
        "## Start a notebook:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cs7f5EXdC0In"
      },
      "source": [
        "For every notebook, we have to set up the google drive and connect the files from the correct directory, otherwise it will not work!\n",
        "\n",
        "\n",
        "*   mount google drive\n",
        "*   go to particular folder where code is located\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u59Ls2qkCzWa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a1dad94-1244-41fc-b146-dbb965b6b9b6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount ('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFuoaD7Jmufj",
        "outputId": "f05ded23-422a-4b51-ca9a-72fb25d0fa56"
      },
      "source": [
        "%cd \n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsLEi8n-DTT3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78109f4a-0586-41dd-99a8-e5359d7a1eb9"
      },
      "source": [
        " %cd /content/drive/MyDrive/fastai-v3/course-v3/nbs/dl2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/fastai-v3/course-v3/nbs/dl2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_-uLVPS3mfR"
      },
      "source": [
        "##Check Imports:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD28x6P2CaXw"
      },
      "source": [
        "[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=1850)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4ZrVQZ6nYAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9495d2fe-0d80-4780-faf2-c3171b40fb35"
      },
      "source": [
        "%load_ext autoreload \n",
        "#will auto reload external references or files\n",
        "%autoreload 2 \n",
        "#and will do so on a specific interval\n",
        "\n",
        "%matplotlib inline \n",
        "#will plot in the notebook"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "of7aVIx-4Q_x"
      },
      "source": [
        "When we code, there are always mistakes, so we have to debug.\n",
        "\n",
        "On this course, we will learn to make tests. Tests help to see bugs easily and they also make it easier to modify the code later.\n",
        "\n",
        "One easy way to do this is to check variables and assigned values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGz1gwd2AwEi"
      },
      "source": [
        "Explenation of next cell: \n",
        "\n",
        "*   comment #export tells the system a cell that you want to keep and reuse.\n",
        "*   We can then import the exported module using: from exp.nb_00 import *  we should be able to import the variable TEST\n",
        "*   Create a test framework\n",
        "test and test_eq using assert\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F308jAuLCaXx"
      },
      "source": [
        "#export\n",
        "from exp.nb_00 import *\n",
        "import operator\n",
        "\n",
        "def test(a,b,cmp,cname=None):\n",
        "    if cname is None: cname=cmp.__name__\n",
        "    assert cmp(a,b),f\"{cname}:\\n{a}\\n{b}\"\n",
        "\n",
        "def test_eq(a,b): test(a,b,operator.eq,'==')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iApXrUoDNTV"
      },
      "source": [
        "* Q: what is assert? what does it do?\n",
        "* A: The assert keyword is used when debugging code.\n",
        "\n",
        "The assert keyword lets you test if a condition in your code returns True, if not, the program will raise an AssertionError."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeO7QbTYBAyv"
      },
      "source": [
        "##expanded test cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjFsPSdXBiXu"
      },
      "source": [
        "from exp.nb_lesson8 import *\n",
        "import operator\n",
        "\n",
        "\n",
        "def test(a, b, cmp, cname=None):\n",
        "    \"\"\"\n",
        "    Simple test function\n",
        "    \"\"\"\n",
        "    # if no name is passed, \n",
        "    if cname is None: \n",
        "        cname=cmp.__name__\n",
        "\n",
        "    # this is the test\n",
        "    # if it fails, the second phrase will be returned\n",
        "    # which is the f\"{cname}:\\n{a}\\n{b}\"\n",
        "    assert cmp(a, b), f\"{cname}:\\n{a}\\n{b}\"\n",
        "\n",
        "def test_eq(a,b):\n",
        "    \"\"\"\n",
        "    Is a larger function that calls the test function\n",
        "    but only passes teh == sign\n",
        "    \"\"\"\n",
        "    test(a, b, operator.eq, '==')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iokHVWJQBgQY"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmyMgPSQBY0d"
      },
      "source": [
        "## Run a sample test:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBtcjyCJCaX9"
      },
      "source": [
        "test_eq(TEST,'test') \n",
        "#If correct, you wonâ€™t get any feedback"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wsOCmEbUoV5w",
        "outputId": "666d88ab-f385-4285-818c-bcaccd0e2edb"
      },
      "source": [
        "#print variable TEST\n",
        "TEST"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'test'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "FwhBGngKDphJ",
        "outputId": "41485df3-81c1-4015-f643-7bf4bd4e3210"
      },
      "source": [
        "test_eq(TEST, \"nottest\") \n",
        "#If it was wrong, we get a message as follows"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-334cc6107809>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"nottest\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#If it was wrong, we get a message as follows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-d2bff91f5bd0>\u001b[0m in \u001b[0;36mtest_eq\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf\"{cname}:\\n{a}\\n{b}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'=='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-d2bff91f5bd0>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(a, b, cmp, cname)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf\"{cname}:\\n{a}\\n{b}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'=='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: ==:\ntest\nnottest"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXBYu5PU-KxL"
      },
      "source": [
        "Explenation of following cell:\n",
        "\n",
        "*   Use run_notebook.py to run the tests outside of the jupyter notebook\n",
        "*   python run_notebook.py 01_matmul.ipynb run the tests outside of the jupyter notebook\n",
        "\n",
        "* Prerequistes: pip install fire\n",
        "* fire takes any function and turns it into a command line interface, this manages arguments and other input values\n",
        "\n",
        "\n",
        "We can see the assertion error when running in the terminal\n",
        "\n",
        "Now we have an automatable unit test framework on jupyter notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "204BQaoXCaX-"
      },
      "source": [
        "# To run tests in console:\n",
        "#! pip install fire\n",
        "#! python run_notebook.py 01_matmul.ipynb"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vqAGswhCaYA"
      },
      "source": [
        "## ERROR Get data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0ecbbLPCaYC"
      },
      "source": [
        "[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=2159)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDXZmb0xCaYG"
      },
      "source": [
        "#export\n",
        "\n",
        "# standard libraries\n",
        "from pathlib import Path\n",
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "import pickle, gzip, math, torch, matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#  datasets\n",
        "from fastai import datasets\n",
        "\n",
        "#  basic pytorch\n",
        "from torch import tensor\n",
        "\n",
        "MNIST_URL='http://deeplearning.net/data/mnist/mnist.pkl'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS_qABAcCaYQ"
      },
      "source": [
        "#path = datasets.download_data(MNIST_URL, ext='.gz'); path"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLduLhQnCaYR"
      },
      "source": [
        "#with gzip.open(path, 'rb') as f:\n",
        " #   ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shb_xea6CaYR",
        "outputId": "371d85f7-284f-423d-baf3-9d2116f84eb6"
      },
      "source": [
        "#x_train,y_train,x_valid,y_valid = map(tensor, (x_train,y_train,x_valid,y_valid))\n",
        "#n,c = x_train.shape\n",
        "#x_train, x_train.shape, y_train, y_train.shape, y_train.min(), y_train.max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
              " torch.Size([50000, 784]),\n",
              " tensor([5, 0, 4,  ..., 8, 4, 8]),\n",
              " torch.Size([50000]),\n",
              " tensor(0),\n",
              " tensor(9))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOovo0-kGMV_"
      },
      "source": [
        "##Correct \"get data\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aOfr3HAhGBH"
      },
      "source": [
        "#export\n",
        "\n",
        "# standard libraries\n",
        "from pathlib import Path\n",
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "import pickle, gzip, math, torch, matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#  datasets\n",
        "from fastai import datasets\n",
        "\n",
        "#  basic pytorch\n",
        "from torch import tensor\n",
        "\n",
        "MNIST_URL='http://deeplearning.net/data/mnist/mnist.pkl'"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsvEiIs7pwTp"
      },
      "source": [
        "def get_data():\n",
        "\n",
        "    #import dataset\n",
        "    import os\n",
        "    import torchvision.datasets as datasets\n",
        "\n",
        "    #store in data folder\n",
        "    root = '../data'\n",
        "    if not os.path.exists(root):\n",
        "        os.mkdir(root)\n",
        "\n",
        "    #create train data set and test dataset:\n",
        "\n",
        "    #train dataset will be downloaded and used for training     \n",
        "    train_set = datasets.MNIST(root=root, train=True, download=True)\n",
        "    \n",
        "    #test dataset will be downloaded BUT NOT used for training\n",
        "    test_set = datasets.MNIST(root=root, train=False, download=True)\n",
        "\n",
        "    #split train dataset into validation dataset and train dataset \n",
        "    #the size of train dataset is 50000\n",
        "    #the size of validation dataset is 50000\n",
        "    x_train, x_valid = train_set.data.split([50000, 10000])\n",
        "    y_train, y_valid = train_set.targets.split([50000, 10000])\n",
        "    return (x_train.view(50000, -1) / 256.0), y_train.float(), (x_valid.view(10000, -1))/ 256.0, y_valid.float()\n",
        "\n",
        "x_train,y_train,x_valid,y_valid = get_data()\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qsf97b8zp_MW",
        "outputId": "9e7c6279-7c1f-46a7-8a53-7add8006e8bc"
      },
      "source": [
        "# store the number of \n",
        "# n = rows\n",
        "# c = columns\n",
        "\n",
        "n,c = x_train.shape\n",
        "\n",
        "# take a look at the values and the shapes\n",
        "x_train, x_train.shape, y_train, y_train.shape, y_train.min(), y_train.max()\n",
        "#our data:\n",
        "#x_train is a table with 500000 rows"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
              " torch.Size([50000, 784]),\n",
              " tensor([5., 0., 4.,  ..., 8., 4., 8.]),\n",
              " torch.Size([50000]),\n",
              " tensor(0.),\n",
              " tensor(9.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itfxHDmWi6Bo"
      },
      "source": [
        "## Let's take a look at our data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlJLHItguRnr",
        "outputId": "bde050fa-a2a5-42e2-b295-e670c9cf7d41"
      },
      "source": [
        "import numpy\n",
        "numpy.sqrt(c)\n",
        "#the image is 28 by 28\n",
        "#this is a matrix, but in ml a vector "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNpBtS_8q222",
        "outputId": "0eeae3a3-e20b-4cac-be5f-e8e4797dc52c"
      },
      "source": [
        "len (x_train), len (y_train), x_train[1], y_train[1] \n",
        "#input, x, binary image in matrix repesentation\n",
        "#output, y, label: digit from 0 to 9\n",
        "#first element of xtrain\n",
        "#the elements in this matrix represent a picture, eg. 0 represents black color"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000,\n",
              " 50000,\n",
              " tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.1992, 0.6211, 0.9883, 0.6211, 0.1953, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.1875, 0.9297, 0.9844, 0.9844, 0.9844, 0.9258, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.2109, 0.8867, 0.9883, 0.9844, 0.9336, 0.9102, 0.9844, 0.2227,\n",
              "         0.0234, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0391, 0.2344, 0.8750, 0.9844, 0.9883, 0.9844, 0.7891, 0.3281, 0.9844,\n",
              "         0.9883, 0.4766, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.6367, 0.9844, 0.9844, 0.9844, 0.9883, 0.9844, 0.9844, 0.3750,\n",
              "         0.7383, 0.9883, 0.6523, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.1992, 0.9297, 0.9883, 0.9883, 0.7422, 0.4453, 0.9883, 0.8906,\n",
              "         0.1836, 0.3086, 0.9961, 0.6562, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.1875, 0.9297, 0.9844, 0.9844, 0.6992, 0.0469, 0.2930, 0.4727,\n",
              "         0.0820, 0.0000, 0.0000, 0.9883, 0.9492, 0.1953, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.1484, 0.6445, 0.9883, 0.9102, 0.8125, 0.3281, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.9883, 0.9844, 0.6445, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0273, 0.6953, 0.9844, 0.9375, 0.2773, 0.0742, 0.1094, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9883, 0.9844, 0.7617, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.2227, 0.9844, 0.9844, 0.2461, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9883, 0.9844, 0.7617,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.7734, 0.9883, 0.7422, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9961, 0.9883,\n",
              "         0.7656, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.2969, 0.9609, 0.9844, 0.4375, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9883,\n",
              "         0.9844, 0.5781, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.3320, 0.9844, 0.8984, 0.0977, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0273, 0.5273,\n",
              "         0.9883, 0.7266, 0.0469, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3320, 0.9844, 0.8711, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0273, 0.5117,\n",
              "         0.9844, 0.8789, 0.2773, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3320, 0.9844, 0.5664,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1875, 0.6445,\n",
              "         0.9844, 0.6758, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3359, 0.9883,\n",
              "         0.8789, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4453, 0.9297,\n",
              "         0.9883, 0.6328, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3320,\n",
              "         0.9844, 0.9727, 0.5703, 0.1875, 0.1133, 0.3320, 0.6953, 0.8789, 0.9883,\n",
              "         0.8711, 0.6523, 0.2188, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.3320, 0.9844, 0.9844, 0.9844, 0.8945, 0.8398, 0.9844, 0.9844, 0.9844,\n",
              "         0.7656, 0.5078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.1094, 0.7773, 0.9844, 0.9844, 0.9883, 0.9844, 0.9844, 0.9102,\n",
              "         0.5664, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0977, 0.5000, 0.9844, 0.9883, 0.9844, 0.5508,\n",
              "         0.1445, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000]),\n",
              " tensor(0.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37Q7RcI0vrOB",
        "outputId": "78d55882-c642-48ba-91eb-d6e87f781a5a"
      },
      "source": [
        "x_valid, x_valid.shape, y_valid, y_valid.shape, y_valid.min(), y_valid.max()\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
              " torch.Size([10000, 784]),\n",
              " tensor([3., 8., 6.,  ..., 5., 6., 8.]),\n",
              " torch.Size([10000]),\n",
              " tensor(0.),\n",
              " tensor(9.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBFqr3wCwCWP",
        "outputId": "a1798e39-fb57-4a22-e752-5a1964f98166"
      },
      "source": [
        "n, y_train.shape[0]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 50000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJQkekYfjDED"
      },
      "source": [
        "#Lets test our input data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z8VxUvxjK7A"
      },
      "source": [
        "1. row check: check that the number of rows in x_train is teh same shape as y_train and that number should be 50,000\n",
        "2. column check: check that number of columns is 28*28 because that is the total number of pixels of the unrolled images\n",
        "3. classes check: test that there are 10 different classes found in y_train: 0 - 9\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WB6oHXeCaYa"
      },
      "source": [
        "assert n==y_train.shape[0]==50000\n",
        "test_eq(c,28*28)\n",
        "test_eq(y_train.min(),0)\n",
        "test_eq(y_train.max(),9)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHtRy3JRoCgC"
      },
      "source": [
        "In case we made some mistakes when we imported the dataset this should cause an error which will tell us that there is something wrong and we should fix it before moving on.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W_0MpbeCaYb"
      },
      "source": [
        "mpl.rcParams['image.cmap'] = 'gray'\n",
        "#matplotlib mpl will use gray scale \n",
        "#since we are going to be working with MNIST"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eatFWuR2CaYb"
      },
      "source": [
        "img = x_train[0]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_ztrm7mCaYd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d86d878a-19fd-4a6e-ab52-9799f323121f"
      },
      "source": [
        "img.view(28,28).type()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'torch.FloatTensor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpisjlW3z3Zs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85a57def-ded8-4162-90bd-32e19c9bbccb"
      },
      "source": [
        "img"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0117,\n",
              "        0.0703, 0.0703, 0.0703, 0.4922, 0.5312, 0.6836, 0.1016, 0.6484, 0.9961,\n",
              "        0.9648, 0.4961, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1172, 0.1406, 0.3672, 0.6016,\n",
              "        0.6641, 0.9883, 0.9883, 0.9883, 0.9883, 0.9883, 0.8789, 0.6719, 0.9883,\n",
              "        0.9453, 0.7617, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1914, 0.9297, 0.9883, 0.9883,\n",
              "        0.9883, 0.9883, 0.9883, 0.9883, 0.9883, 0.9883, 0.9805, 0.3633, 0.3203,\n",
              "        0.3203, 0.2188, 0.1523, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0703, 0.8555, 0.9883,\n",
              "        0.9883, 0.9883, 0.9883, 0.9883, 0.7734, 0.7109, 0.9648, 0.9414, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3125,\n",
              "        0.6094, 0.4180, 0.9883, 0.9883, 0.8008, 0.0430, 0.0000, 0.1680, 0.6016,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0547, 0.0039, 0.6016, 0.9883, 0.3516, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.5430, 0.9883, 0.7422, 0.0078, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0430, 0.7422, 0.9883, 0.2734,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1367, 0.9414,\n",
              "        0.8789, 0.6250, 0.4219, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.3164, 0.9375, 0.9883, 0.9883, 0.4648, 0.0977, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.1758, 0.7266, 0.9883, 0.9883, 0.5859, 0.1055, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0625, 0.3633, 0.9844, 0.9883, 0.7305,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9727, 0.9883,\n",
              "        0.9727, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1797, 0.5078, 0.7148, 0.9883,\n",
              "        0.9883, 0.8086, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.1523, 0.5781, 0.8945, 0.9883, 0.9883,\n",
              "        0.9883, 0.9766, 0.7109, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0938, 0.4453, 0.8633, 0.9883, 0.9883, 0.9883,\n",
              "        0.9883, 0.7852, 0.3047, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0898, 0.2578, 0.8320, 0.9883, 0.9883, 0.9883, 0.9883,\n",
              "        0.7734, 0.3164, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0703, 0.6680, 0.8555, 0.9883, 0.9883, 0.9883, 0.9883, 0.7617,\n",
              "        0.3125, 0.0352, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.2148, 0.6719, 0.8828, 0.9883, 0.9883, 0.9883, 0.9883, 0.9531, 0.5195,\n",
              "        0.0430, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.5312, 0.9883, 0.9883, 0.9883, 0.8281, 0.5273, 0.5156, 0.0625,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srBH8drYCaYe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "9abf5f5d-59e6-4e22-f3ac-8a1d45a930be"
      },
      "source": [
        "plt.imshow(img.view((28,28)));\n",
        "# note that there is a single vector \n",
        "#that is reshaped into the square format"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBTmQxO3CaZe"
      },
      "source": [
        "## Initial python model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHpr-VcWCaZe"
      },
      "source": [
        " [Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=2342)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiC1anwTCaZf"
      },
      "source": [
        " [Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=2342)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b3rcyCuoUbR"
      },
      "source": [
        "Linear model: y = ax + b\n",
        "\n",
        "a = weights\n",
        "\n",
        "b = bias/baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MaZIzlkCaZg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3be7dd3-f8a1-4621-8b40-9e5413c53665"
      },
      "source": [
        "weights = torch.randn(784,10); weights\n",
        "#Weights receives random values 784 in and 10 out\n",
        "#784 is the size of image, 28x28\n",
        "#10 is the number of outputs, digits 0 to 9"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.5705,  1.3106,  1.2236,  ...,  1.1236, -0.1651,  0.1648],\n",
              "        [-0.6423, -0.3147, -2.2214,  ..., -0.3883,  1.3296, -1.6539],\n",
              "        [ 1.1899,  0.8837,  1.3122,  ..., -0.9088, -0.7031, -0.3882],\n",
              "        ...,\n",
              "        [ 0.3033,  0.8659,  0.3883,  ..., -0.0247, -0.2455,  0.4175],\n",
              "        [-0.0302, -0.9895,  0.0950,  ...,  1.3713,  1.2330, -0.2486],\n",
              "        [-0.1475, -1.2076,  0.1044,  ..., -0.2375, -0.5408,  0.1602]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4rMpc6oCaZh"
      },
      "source": [
        "bias = torch.zeros(10)\n",
        "#Bias initialized with zeros"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-1a2W1pCaZh"
      },
      "source": [
        "#### Matrix multiplication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb9StbPg-FQp"
      },
      "source": [
        "Function of matrix multiplication\n",
        "\n",
        "review of matrix multiplication from [matrixmultiplication.xyz](https://)\n",
        "\n",
        "The following function multiplies two arrays element by element\n",
        "\n",
        "A few loops going on: three"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzgAsFHpCaZi"
      },
      "source": [
        "def matmul(a,b):\n",
        "\n",
        "    # gets the shapes of the input arrays\n",
        "    ar,ac = a.shape # n_rows * n_cols\n",
        "    br,bc = b.shape\n",
        "\n",
        "    # checks to make sure that the\n",
        "    # inner dimensions are the same\n",
        "    assert ac==br\n",
        "\n",
        "    # initializes the new \n",
        "    #c receives zeros with shape ar and br\n",
        "    c = torch.zeros(ar, bc)\n",
        "\n",
        "    # loops by row in A\n",
        "    for i in range(ar):\n",
        "\n",
        "        # loops by col in B\n",
        "        for j in range(bc):\n",
        "\n",
        "            # for each value\n",
        "            for k in range(ac): # or br\n",
        "                c[i,j] += a[i,k] * b[k,j]\n",
        "    return c"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE65VYWRqsFP"
      },
      "source": [
        "Queick sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h4oQ1eLCaZi"
      },
      "source": [
        "#Will use the first 5 images from the validation data \n",
        "#and multiply them by the weights of the matrix\n",
        "\n",
        "m1 = x_valid[:5]\n",
        "m2 = weights"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDmlY37MCaZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f9c7388-e88b-4cb9-d831-545874edc356"
      },
      "source": [
        "m1.shape,m2.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 784]), torch.Size([784, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5V2VBYILCaZk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d42c8b4e-28f7-4b69-c1ac-aaeef556ef7d"
      },
      "source": [
        "%time t1=matmul(m1, m2)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 785 ms, sys: 0 ns, total: 785 ms\n",
            "Wall time: 787 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVfZ44b9-BnZ"
      },
      "source": [
        "This method is correct but very slow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI8x6_xHCaZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3607702a-f8be-4ef8-a215-6d9130381922"
      },
      "source": [
        "t1.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwRh48pKCaZv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bb51192-69b3-4186-b2fd-8828d8759ea7"
      },
      "source": [
        "len(x_train)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pG4Xtd0krFp_"
      },
      "source": [
        "How can we do this 50,000 times faster? \n",
        "\n",
        "\n",
        "We can do this with element-wise operations. We will use pytorchâ€™s tensor to illustrate this. When using pytorch objects, Operators (+,-,*,/,>,<,==) are usually element-wise. Examples of element-wise operations:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgymkKKRCaZw"
      },
      "source": [
        "#### Elementwise ops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEK-7ADiCaZw"
      },
      "source": [
        "Operators (+,-,\\*,/,>,<,==) are usually element-wise.\n",
        "\n",
        "Examples of element-wise operations:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTSjwUriCaZx"
      },
      "source": [
        " [Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=2682)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IF2fCGV-Rju"
      },
      "source": [
        "What is a tensor? ML jargon for matrix and vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-W-6Lz5CaZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b6fbb0f-9f34-42d3-e712-4060ceeb5bf4"
      },
      "source": [
        "a = tensor([10., 6, -4])\n",
        "b = tensor([2., 8, 7])\n",
        "a,b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([10.,  6., -4.]), tensor([2., 8., 7.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_HCG61N_R4O"
      },
      "source": [
        "In ordinary programming, you should use loops to add vectors. But if you do it element wise you don't need it, so it's faster\n",
        "\n",
        "In ML, the computation happens in parallel. That's why it's fast. But in order to use this, we need to use GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzxogBv8CaZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc1f3c45-efe3-4c4a-ddd5-5141b1094663"
      },
      "source": [
        "a + b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12., 14.,  3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63qB23yoCaZy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa7fbce0-5a1d-41f5-8d22-9a5d5086f3a1"
      },
      "source": [
        "(a < b),(a < b).float(),(a < b).float().mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([False,  True,  True]), tensor([0., 1., 1.]), tensor(0.6667))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MudUadL5CaZy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22032aea-c50f-4d6b-e34d-f6ed3c146557"
      },
      "source": [
        "m = tensor([[1., 2, 3], [4,5,6], [7,8,9]]); m"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.],\n",
              "        [7., 8., 9.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7L6j4wRCaZz"
      },
      "source": [
        "Frobenius norm:\n",
        "\n",
        "$$\\| A \\|_F = \\left( \\sum_{i,j=1}^n | a_{ij} |^2 \\right)^{1/2}$$\n",
        "\n",
        "*Hint*: you don't normally need to write equations in LaTeX yourself, instead, you can click 'edit' in Wikipedia and copy the LaTeX from there (which is what I did for the above equation). Or on arxiv.org, click \"Download: Other formats\" in the top right, then \"Download source\"; rename the downloaded file to end in `.tgz` if it doesn't already, and you should find the source there, including the equations to copy and paste."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-qsaqnVAQSh"
      },
      "source": [
        "What is the magnitute of a matrix? What's the point of it?\n",
        "\n",
        "Very often the matrix represents some complicated quantitude, so we may need the magnitude.\n",
        "\n",
        "How do we calculate the magnitude? Frobenius norm\n",
        "\n",
        "flatten vector and calculate it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7BneoFMCG5U",
        "outputId": "6e6fdfda-8b06-405e-9576-39a1f9767c3c"
      },
      "source": [
        "mr,mc = m.shape;mr,mc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuKm5X67AOwm",
        "outputId": "6f653e9b-e38a-4198-b061-c95174d74ba3"
      },
      "source": [
        "(m*m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.,  4.,  9.],\n",
              "        [16., 25., 36.],\n",
              "        [49., 64., 81.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph6VeBGABRrw",
        "outputId": "2646ee66-3d24-474c-9213-bb2dacb95ccc"
      },
      "source": [
        "(m*m).sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(285.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW0wEb3SCaZ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "602d09aa-040c-46bf-cb1c-215a87ce6d08"
      },
      "source": [
        "(m*m).sum().sqrt()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(16.8819)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASvJBdULCaZ1"
      },
      "source": [
        "#### Elementwise matmul"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yX_CEHdTEsWP",
        "outputId": "f025a00e-74ba-48f4-b123-5de9c5ff200e"
      },
      "source": [
        "m"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.],\n",
              "        [7., 8., 9.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfOg22EjEjJ4",
        "outputId": "1cdc8df2-e384-4b76-8bbb-65865860d07c"
      },
      "source": [
        "m[:,0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 4., 7.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6exh-JPEfYM",
        "outputId": "ead7415f-59ca-4ffe-9854-b01586c5c017"
      },
      "source": [
        "m[0,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1sBT6fsr8MJ"
      },
      "source": [
        "###If we adjust the matmul...\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-z-8_sJsFyu"
      },
      "source": [
        "for k in range(ac): # or br\n",
        "    c[i,j] += a[i,k] * b[k,j]\n",
        "#will be replaced by\n",
        "\n",
        "c[i,j] = (a[i,:] * b[:,j]).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stccT2zertr8"
      },
      "source": [
        "This is the same thing as previously but now we calculate the whole row/column at a time. This is 178 times faster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOQcwNKnCaZ2"
      },
      "source": [
        "def matmul(a,b):\n",
        "\n",
        "    # gets the shapes of the input arrays\n",
        "    ar,ac = a.shape # n_rows * n_cols\n",
        "    br,bc = b.shape\n",
        "\n",
        "    # checks to make sure that the\n",
        "    # inner dimensions are the same\n",
        "    assert ac==br\n",
        "\n",
        "    # initializes the new array\n",
        "    c = torch.zeros(ar, bc)\n",
        "\n",
        "    # loops by row in A\n",
        "    for i in range(ar):\n",
        "\n",
        "        # loops by col in B\n",
        "        for j in range(bc):\n",
        "          \n",
        "            # Any trailing \",:\" can be removed\n",
        "            c[i,j] = (a[i,:] * b[:,j]).sum()\n",
        "    return c"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhgMyfO3CaZ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd57bf8f-1609-4aee-d54a-345d4af7a1fe"
      },
      "source": [
        "%timeit -n 10 _=matmul(m1, m2)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 5: 1.04 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xryXir7MCaZ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7296e81-98d9-46bd-8faf-634e184e2c31"
      },
      "source": [
        "804/5"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "160.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuQU90qhGuSn"
      },
      "source": [
        "Q: What is this near test?\n",
        "\n",
        "A: Another function to compare matrices. \n",
        "\n",
        "The reason for this test is that due to rounding errors from math operations, matrices may not be exactly the same. As a result, we want a function that will â€œis a equal to b within some toleranceâ€"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-sWnHDoCaZ8"
      },
      "source": [
        "#export\n",
        "def near(a,b): \n",
        "    return torch.allclose(a, b, rtol=1e-3, atol=1e-5)\n",
        "def test_near(a,b): \n",
        "    test(a,b,near)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1ppuucwCaZ9"
      },
      "source": [
        "test_near(t1,matmul(m1, m2))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-TjhbmmCaZ9"
      },
      "source": [
        "### Broadcasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnaaClVyCaaB"
      },
      "source": [
        "The term **broadcasting** describes how arrays with different shapes are treated during arithmetic operations.  The term broadcasting was first used by Numpy.\n",
        "\n",
        "From the [Numpy Documentation](https://docs.scipy.org/doc/numpy-1.10.0/user/basics.broadcasting.html):\n",
        "\n",
        "    The term broadcasting describes how numpy treats arrays with \n",
        "    different shapes during arithmetic operations. Subject to certain \n",
        "    constraints, the smaller array is â€œbroadcastâ€ across the larger \n",
        "    array so that they have compatible shapes. Broadcasting provides a \n",
        "    means of vectorizing array operations so that looping occurs in C\n",
        "    instead of Python. It does this without making needless copies of \n",
        "    data and usually leads to efficient algorithm implementations.\n",
        "    \n",
        "In addition to the efficiency of broadcasting, it allows developers to write less code, which typically leads to fewer errors.\n",
        "\n",
        "*This section was adapted from [Chapter 4](http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/4.%20Compressed%20Sensing%20of%20CT%20Scans%20with%20Robust%20Regression.ipynb#4.-Compressed-Sensing-of-CT-Scans-with-Robust-Regression) of the fast.ai [Computational Linear Algebra](https://github.com/fastai/numerical-linear-algebra) course.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IHCEmY7Caax"
      },
      "source": [
        "[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=3110)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM-QjoTMCaay"
      },
      "source": [
        "#### Broadcasting with a scalar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UIsnNGtCaay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e61bdf41-0982-414c-8c9d-9b496189967f"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10.,  6., -4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWze6_8AHJ_O",
        "outputId": "01b4733b-386f-4b4f-a5e7-f15076db47fe"
      },
      "source": [
        "a> tensor([0,0,0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ True,  True, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8iGaGqfCaaz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "febe9b6a-08d8-4b6d-e3cf-c59a982d9a05"
      },
      "source": [
        "a > 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ True,  True, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzwk5KADCaa3"
      },
      "source": [
        "How are we able to do a > 0?  0 is being **broadcast** to have the same dimensions as a.\n",
        "\n",
        "For instance you can normalize our dataset by subtracting the mean (a scalar) from the entire data set (a matrix) and dividing by the standard deviation (another scalar), using broadcasting.\n",
        "\n",
        "Other examples of broadcasting with a scalar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eBKcUCMCaa4",
        "outputId": "8ea4511a-d2f1-43f5-85c6-15f25b38e5e9"
      },
      "source": [
        "a + 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11.,  7., -3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6dwZhD7Caa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fa12ec6-be55-4bd6-83ca-70bae7c5c71f"
      },
      "source": [
        "m"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.],\n",
              "        [7., 8., 9.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKSYqvTzCabA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1161bf6-c0e5-48c0-c6b2-90aa458c6778"
      },
      "source": [
        "2*m"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.,  4.,  6.],\n",
              "        [ 8., 10., 12.],\n",
              "        [14., 16., 18.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb5OgTIouTRq"
      },
      "source": [
        "How are we able to do a > 0? 0 is being broadcast to have the same dimensions as a.\n",
        "\n",
        "For instance you can normalize our dataset by subtracting the mean (a scalar) from the entire data set (a matrix) and dividing by the standard deviation (another scalar), using broadcasting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byrSkz1qCabA"
      },
      "source": [
        "#### Broadcasting a vector to a matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNFSzLQcCabB"
      },
      "source": [
        "We can also broadcast a vector to a matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuJCMTsmCabC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d6b89d2-3b03-4381-8834-a378d145be2a"
      },
      "source": [
        "c = tensor([10.,20,30]); c"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10., 20., 30.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J57nzDINCabC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f54a792e-0420-4260-e35d-50988ff7a99a"
      },
      "source": [
        "m"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.],\n",
              "        [7., 8., 9.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kUvUY8vCabD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a76b5dc-24ce-429f-b164-a31ceb63b1f0"
      },
      "source": [
        "m.shape,c.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 3]), torch.Size([3]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xczqdHngCabD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "add47e07-3ddc-4cf6-e718-ef9344149cf7"
      },
      "source": [
        "m + c"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[11., 22., 33.],\n",
              "        [14., 25., 36.],\n",
              "        [17., 28., 39.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMePW-5TCabE",
        "outputId": "b05c714a-5d42-4cd3-84a0-9509e659988f"
      },
      "source": [
        "c + m"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[11., 22., 33.],\n",
              "        [14., 25., 36.],\n",
              "        [17., 28., 39.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hIJ2eQtCabF"
      },
      "source": [
        "We don't really copy the rows, but it looks as if we did. In fact, the rows are given a *stride* of 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3kOZM30CabF"
      },
      "source": [
        "t = c.expand_as(m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92apIlTVCabF",
        "outputId": "2fda6c29-f2df-4853-f7ed-bf9fa5eabded"
      },
      "source": [
        "t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10., 20., 30.],\n",
              "        [10., 20., 30.],\n",
              "        [10., 20., 30.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_k8wzYvCabG",
        "outputId": "3ad41cf5-83e0-449c-c497-01693b9de695"
      },
      "source": [
        "m + t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[11., 22., 33.],\n",
              "        [14., 25., 36.],\n",
              "        [17., 28., 39.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az_tUvEhCabG",
        "outputId": "5cad9ed2-e6fe-44a7-92cd-0f1982d9c955"
      },
      "source": [
        "# even though it may appear to be a 3x3, if we \n",
        "# look at the memory, its only storing a single copy\n",
        "t.storage()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 10.0\n",
              " 20.0\n",
              " 30.0\n",
              "[torch.FloatStorage of size 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMniBDDmCabG",
        "outputId": "48dcbf05-4f31-4fb6-9ef9-3d23f14610e2"
      },
      "source": [
        "# the stride, tells when it is going\n",
        "# row to row, it takes 0 steps (constant values)\n",
        "# column to column it takes 1 step\n",
        "t.stride(), t.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((0, 1), torch.Size([3, 3]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h_-XCkvCabH"
      },
      "source": [
        "You can index with the special value [None] or use `unsqueeze()` to convert a 1-dimensional array into a 2-dimensional array (although one of those dimensions has value 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDrEJUDACabH",
        "outputId": "fc2ad12a-da37-4cec-d53b-83e278cf9d12"
      },
      "source": [
        "c.unsqueeze(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10., 20., 30.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D21xacTaCabH",
        "outputId": "5d29ee85-f346-40ed-8cde-a4877150e902"
      },
      "source": [
        "c.unsqueeze(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10.],\n",
              "        [20.],\n",
              "        [30.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqRjHuZYCabH",
        "outputId": "c7a02094-5fd0-44c1-f393-1e85a77df8bd"
      },
      "source": [
        "m"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.],\n",
              "        [7., 8., 9.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWF1duUUCabI",
        "outputId": "bc282e81-b7b9-424a-e99e-94bb92f9cc08"
      },
      "source": [
        "c.shape, c.unsqueeze(0).shape,c.unsqueeze(1).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.Size([1, 3]), torch.Size([3, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NuMGKGeCabI",
        "outputId": "2501a95d-4222-494b-8237-164ee14e19eb"
      },
      "source": [
        "c.shape, c[None].shape,c[:,None].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.Size([1, 3]), torch.Size([3, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHFo-SEVCabI"
      },
      "source": [
        "Note the change from a size 3 to a 1 x 3 or a 3 x 1.\n",
        "\n",
        "The syntax can also be shortened as follows:\n",
        "\n",
        "You can always skip trailling ':'s. And '...' means '*all preceding dimensions*'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkr2lYcWCabJ",
        "outputId": "fb20d281-e08a-4584-c953-f08a6273a068"
      },
      "source": [
        "c[None].shape,c[...,None].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 3]), torch.Size([3, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7cpR3M-CabJ",
        "outputId": "23636003-17f7-4578-b9a6-174608a5c36a"
      },
      "source": [
        "c[:,None].expand_as(m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10., 10., 10.],\n",
              "        [20., 20., 20.],\n",
              "        [30., 30., 30.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzAlwqMtCabJ",
        "outputId": "b27d5808-622b-4877-f050-1e4f714ef900"
      },
      "source": [
        "m + c[:,None]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[11., 12., 13.],\n",
              "        [24., 25., 26.],\n",
              "        [37., 38., 39.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9gftYevCabK",
        "outputId": "29897186-92d7-4d8d-d8c9-acb7f6ee4e3c"
      },
      "source": [
        "c[:,None]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10.],\n",
              "        [20.],\n",
              "        [30.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHN-Uv8HCabN"
      },
      "source": [
        "#### Matmul with broadcasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mqr88kN_u-r3"
      },
      "source": [
        "Lets take advantage of broadcasting and reduce the loops in our matmul function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw7wVEyjvosV"
      },
      "source": [
        "#we will replace:\n",
        "    # loops  by col in B\n",
        "        for j in range(bc):\n",
        "            \n",
        "            c[i,j] = (a[i,:] * b[:,j]).sum()\n",
        "#with:\n",
        "c[i] = (a[i].unsqueeze(-1) * b).sum(dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "920qjuQqwAU7"
      },
      "source": [
        "So whatâ€™s happening\n",
        "* **a[i,:]** looks at a rank 1 tensor\n",
        "\n",
        "* **.unsqueeze(-1)** makes it 2d, the -1 means the last dimension\n",
        "\n",
        "* **b** broadcast over b\n",
        "\n",
        "* **.sum(dim=0)** sum along the first axis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDg2Q3eDCabP"
      },
      "source": [
        "def matmul(a,b):\n",
        "\n",
        "    #gets the shapes of the input arrays\n",
        "    ar,ac = a.shape #n_rows * n_cols\n",
        "    br,bc = b.shape\n",
        "\n",
        "    #checks to make sure that the \n",
        "    #inner dimensions are the same\n",
        "    assert ac==br\n",
        "\n",
        "    #initializes the new array\n",
        "    c = torch.zeros(ar, bc)\n",
        "\n",
        "    #loops by row in A\n",
        "    for i in range(ar):\n",
        "        #c[i,j] = (a[i,:] * b[:,j]).sum() # previous\n",
        "        c[i]   = (a[i  ].unsqueeze(-1) * b).sum(dim=0)\n",
        "    return c"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbdfOCBeCabV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c97504dc-576d-4088-8735-8ee6ac14bf07"
      },
      "source": [
        "%timeit -n 10 _=matmul(m1, m2)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 5: 189 Âµs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3QAeLnaCabX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1e83478-2c82-4fe4-b335-85fc38973ce1"
      },
      "source": [
        "885000/277"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3194.945848375451"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQZy6lUSCabY"
      },
      "source": [
        "test_near(t1, matmul(m1, m2))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hpl3SGcCabZ"
      },
      "source": [
        "#### Broadcasting Rules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzlqzRmRCabZ",
        "outputId": "b1eaee8b-5466-4daa-cb8f-bd7060ba1611"
      },
      "source": [
        "c[None,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10., 20., 30.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8EZ7nUfCaba",
        "outputId": "b74150b4-5641-4b5e-a778-ffea61d5ceb0"
      },
      "source": [
        "c[None,:].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypp5HQEeCaba",
        "outputId": "ba3aac14-3556-4ed3-ff39-0694ddd1da82"
      },
      "source": [
        "c[:,None]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10.],\n",
              "        [20.],\n",
              "        [30.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ep5zyXaCabb",
        "outputId": "8c0222e8-67f3-45ba-bebf-13a91012b7d2"
      },
      "source": [
        "c[:,None].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md32j9gCCabc",
        "outputId": "3b4fdb7b-7e40-4e0f-cbfc-f9d0e651f9e8"
      },
      "source": [
        "c[None,:] * c[:,None]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[100., 200., 300.],\n",
              "        [200., 400., 600.],\n",
              "        [300., 600., 900.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6OJDJQHCabc",
        "outputId": "a55d869a-72a1-489a-fb3e-f146dc91f83c"
      },
      "source": [
        "c[None] > c[:,None]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 1],\n",
              "        [0, 0, 1],\n",
              "        [0, 0, 0]], dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtcTsWzLCabf"
      },
      "source": [
        "When operating on two arrays/tensors, Numpy/PyTorch compares their shapes element-wise. It starts with the **trailing dimensions**, and works its way forward. Two dimensions are **compatible** when\n",
        "\n",
        "- they are equal, or\n",
        "- one of them is 1, in which case that dimension is broadcasted to make it the same size\n",
        "\n",
        "Arrays do not need to have the same number of dimensions. For example, if you have a `256*256*3` array of RGB values, and you want to scale each color in the image by a different value, you can multiply the image by a one-dimensional array with 3 values. Lining up the sizes of the trailing axes of these arrays according to the broadcast rules, shows that they are compatible:\n",
        "\n",
        "    Image  (3d array): 256 x 256 x 3\n",
        "    Scale  (1d array):             3\n",
        "    Result (3d array): 256 x 256 x 3\n",
        "\n",
        "The [numpy documentation](https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html#general-broadcasting-rules) includes several examples of what dimensions can and can not be broadcast together."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0Ai2gBQCabg"
      },
      "source": [
        "### Einstein summation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJyVbseNCabh"
      },
      "source": [
        "Einstein summation (`einsum`) is a compact representation for combining products and sums in a general way. From the numpy docs:\n",
        "\n",
        "\"The subscripts string is a comma-separated list of subscript labels, where each label refers to a dimension of the corresponding operand. Whenever a label is repeated it is summed, so `np.einsum('i,i', a, b)` is equivalent to `np.inner(a,b)`. If a label appears only once, it is not summed, so `np.einsum('i', a)` produces a view of a with no changes.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukfkN8mCCabh"
      },
      "source": [
        "[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=4280)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wM8g-zACabi"
      },
      "source": [
        "# c[i,j] += a[i,k] * b[k,j]\n",
        "# c[i,j] = (a[i,:] * b[:,j]).sum()\n",
        "def matmul(a,b): return torch.einsum('ik,kj->ij', a, b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEaGfkN5Cabj",
        "outputId": "bb48f623-af13-4466-f68b-d8aefe79da81"
      },
      "source": [
        "%timeit -n 10 _=matmul(m1, m2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "57.2 Âµs Â± 15.3 Âµs per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sved9_2MCabk",
        "outputId": "ecacbbe2-3e85-484a-814e-611cb59337aa"
      },
      "source": [
        "885000/55"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16090.90909090909"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eDVNEmoCabl"
      },
      "source": [
        "test_near(t1, matmul(m1, m2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSZp2i6rCabl"
      },
      "source": [
        "### pytorch op"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdAHUK3JyOnw"
      },
      "source": [
        "Weâ€™ve sped things up, but the pytorch op is optimized even more. Even with vectorized operations, thereâ€™s slow and fast ways of handling memory. Unfortunately most programmers donâ€™t have access to this, short of using functions provided in BLAS libraries (Basic Linear Algebra Subprograms)\n",
        "\n",
        "Topic to look up: Tensor Comprehensions\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUpFerPACabl"
      },
      "source": [
        "We can use pytorch's function or operator directly for matrix multiplication."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHZN1VQ4Cabm"
      },
      "source": [
        "[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=4702)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjCb1XvXyqCt"
      },
      "source": [
        "def matmul(a,b): return a.matmul(b)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW36qb9gy5XR"
      },
      "source": [
        "a.matmul(b) = a@b\n",
        "\n",
        "a = m1\n",
        "\n",
        "b= m2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt-l38QuCabn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e692a0c-af47-4b6d-f967-d38055690a00"
      },
      "source": [
        "%timeit -n 10 t2 = m1.matmul(m2)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 135.50 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10 loops, best of 5: 15.7 Âµs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7vDxeCBx-CG"
      },
      "source": [
        "Because multiplications occur so often thereâ€™s shorthand for this operation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzFwSUBqCabo",
        "outputId": "dd7d4351-28eb-43c8-c9c4-62f7f1722d1e"
      },
      "source": [
        "# time comparison vs pure python:\n",
        "885000/18"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49166.666666666664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TDzhc6ECabo"
      },
      "source": [
        "t2 = m1@m2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jwl9HRwJCabo"
      },
      "source": [
        "test_near(t1, t2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-K4ZTZVCabo",
        "outputId": "e38c60e4-0156-4a93-8d22-49e1b3c770f8"
      },
      "source": [
        "m1.shape,m2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 784]), torch.Size([784, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_-DiYKtzKzQ"
      },
      "source": [
        "This is the best code for this problem we can create using current tools in Python. It is 50,000 times faster than the original code. The reason that this is much faster than einsum is that matmul is designed to calculate one bit at a time which means that numbers donâ€™t need to get from RAM many times. These is done using low-level programming languages. The problem is that we canâ€™t modify these. There are a lot of different CPUs and this is not one size fit for all. We should be available to modify it so that it fits perfectly to our computer. And this time there is no answer to this. PyTorch doesnâ€™t allow you to change those things because of how it is built."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQIlfcDCabp"
      },
      "source": [
        "## Export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aANYO1EuCabp",
        "outputId": "e85545b5-ffa0-47c6-9f2e-77674933b2c5"
      },
      "source": [
        "!python notebook2script.py 01_matmul.ipynb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted 01_matmul.ipynb to nb_01.py\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB600bONCabp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}